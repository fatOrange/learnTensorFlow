{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow  as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data\\train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data\\train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data\\t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data\\t10k-labels-idx1-ubyte.gz\n",
      "lter 0, Testing Accuracy 0.2417\n",
      "lter 1, Testing Accuracy 0.3127\n",
      "lter 2, Testing Accuracy 0.3469\n",
      "lter 3, Testing Accuracy 0.3744\n",
      "lter 4, Testing Accuracy 0.3893\n",
      "lter 5, Testing Accuracy 0.3975\n",
      "lter 6, Testing Accuracy 0.4034\n",
      "lter 7, Testing Accuracy 0.4082\n",
      "lter 8, Testing Accuracy 0.4127\n",
      "lter 9, Testing Accuracy 0.4155\n",
      "lter 10, Testing Accuracy 0.4195\n",
      "lter 11, Testing Accuracy 0.4205\n",
      "lter 12, Testing Accuracy 0.4225\n",
      "lter 13, Testing Accuracy 0.4231\n",
      "lter 14, Testing Accuracy 0.4262\n",
      "lter 15, Testing Accuracy 0.4297\n",
      "lter 16, Testing Accuracy 0.4292\n",
      "lter 17, Testing Accuracy 0.4295\n",
      "lter 18, Testing Accuracy 0.4294\n",
      "lter 19, Testing Accuracy 0.4306\n",
      "lter 20, Testing Accuracy 0.4329\n"
     ]
    }
   ],
   "source": [
    "#载入数据集\n",
    "mnist = input_data.read_data_sets(\"MNIST_data\",one_hot=True)\n",
    "\n",
    "#每个批次的大小\n",
    "batch_size = 100\n",
    "#计算一共有多少个批次\n",
    "n_batch = mnist.train.num_examples//batch_size\n",
    "\n",
    "#定义两个placeholder\n",
    "x = tf.placeholder(tf.float32,[None,784])\n",
    "y = tf.placeholder(tf.float32,[None,10])\n",
    "\n",
    "#创建一共简单的神经网络\n",
    "#为啥三层网络不行？？？？？\n",
    "\n",
    "# W_1 = tf.Variable(tf.zeros([784,100]),name ='w1')\n",
    "# b_1 = tf.Variable(tf.zeros([100]),name = 'b1')\n",
    "\n",
    "# W_2 = tf.Variable(tf.zeros([100,10]),name= 'w2')\n",
    "# b_2 = tf.Variable(tf.zeros([10]),'b2')\n",
    "\n",
    "# 应当注意顺序\n",
    "\n",
    "weights_1 =tf.Variable(tf.random_normal([784,100]))\n",
    "\n",
    "bias_1      =tf.Variable(tf.zeros(100)+0.1)\n",
    "\n",
    "wx_plus_b_1 =tf.matmul(x,weights_1)+bias_1\n",
    "\n",
    "\n",
    "weights_2 =tf.Variable(tf.random_normal([100,10]))\n",
    "\n",
    "bias_2      =tf.Variable(tf.zeros(10)+0.1)\n",
    "\n",
    "layer_1 = tf.nn.relu(wx_plus_b_1)\n",
    "\n",
    "wx_plus_b_2 =tf.matmul(layer_1,weights_2)+bias_2\n",
    "\n",
    "prediction = tf.nn.softmax(wx_plus_b_2)\n",
    "\n",
    "#二次代价函数           \n",
    "loss = tf.reduce_mean(tf.square(y - prediction))\n",
    "#使用梯度下降法\n",
    "train_step = tf.train.GradientDescentOptimizer(0.5).minimize(loss)\n",
    "\n",
    "#初始化变量\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "#结果存放在布尔型列表中\n",
    "correct_prediction = tf.equal(tf.argmax(y,1),tf.argmax(prediction,1)) #argmax返回依一维张量中最大的值的位置\n",
    "#求准确率\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction,tf.float32))# cast把格式转换为32位浮点型\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for epoch in range(21):\n",
    "        for batch in range(n_batch):\n",
    "            batch_xs,batch_ys = mnist.train.next_batch(batch_size)\n",
    "            sess.run(train_step,feed_dict = {x:batch_xs,y:batch_ys})\n",
    "        \n",
    "        acc = sess.run(accuracy,feed_dict = {x:mnist.test.images,y:mnist.test.labels})\n",
    "        print(\"lter \" + str(epoch) + \", Testing Accuracy \"+str(acc))\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3.4151464]]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf# 定义变量\n",
    "w1 = tf.Variable(tf.random_normal([2,3],stddev=1),name=\"w1\")\n",
    "w2 = tf.Variable(tf.random_normal([3,1],stddev=1),name=\"w2\")\n",
    "biases1 = tf.Variable(tf.zeros([3]),name=\"b1\")# 隐藏层的偏向bias[ 0. 0. 0.]\n",
    "biases2 = tf.Variable(tf.zeros([1]),name=\"b2\")# 输出层的偏向bias [0.]\n",
    "x = tf.constant([[0.7,0.9]])# 定义前向传播\n",
    "a = tf.matmul(x,w1) + biases1\n",
    "y = tf.matmul(a,w2) + biases2\n",
    "# 调用会话函数输出\n",
    "with tf.Session()as sess:\n",
    "    init_op = tf.global_variables_initializer()\n",
    "    sess.run(init_op)\n",
    "    print(sess.run(y))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_layer(input_x,in_size,out_size,activation_function=None):\n",
    "\n",
    "    weights   =tf.Variable(tf.random_normal([in_size,out_size]))\n",
    "\n",
    "    bias      =tf.Variable(tf.zeros(out_size)+0.1)\n",
    "\n",
    "    wx_plus_b =tf.matmul(input_x,weights)+bias\n",
    "\n",
    "    if activation_function is None:\n",
    "\n",
    "        outputs=wx_plus_b\n",
    "\n",
    "    else:\n",
    "\n",
    "        outputs=activation_function(wx_plus_b)\n",
    "\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data\\train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data\\train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data\\t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data\\t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "#载入数据集\n",
    "mnist = input_data.read_data_sets(\"MNIST_data\",one_hot=True)\n",
    "\n",
    "#每个批次的大小\n",
    "batch_size = 100\n",
    "#计算一共有多少个批次\n",
    "n_batch = mnist.train.num_examples//batch_size\n",
    "\n",
    "#定义两个placeholder\n",
    "x = tf.placeholder(tf.float32,[None,784])\n",
    "y = tf.placeholder(tf.float32,[None,10])\n",
    "\n",
    "#创建一共简单的神经网络\n",
    "#为啥三层网络不行？？？？？\n",
    "\n",
    "hidden_layer_out = add_layer(x,784,100,activation_function=tf.nn.relu)\n",
    "prediction = add_layer(hidden_layer_out,100,10,activation_function=tf.nn.softmax)\n",
    "\n",
    "\n",
    "\n",
    "#二次代价函数           \n",
    "loss = tf.reduce_mean(tf.square(y - prediction))\n",
    "#使用梯度下降法\n",
    "train_step = tf.train.GradientDescentOptimizer(0.01).minimize(loss)\n",
    "\n",
    "#初始化变量\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "#结果存放在布尔型列表中\n",
    "correct_prediction = tf.equal(tf.argmax(y,1),tf.argmax(prediction,1)) #argmax返回依一维张量中最大的值的位置\n",
    "#求准确率\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction,tf.float32))# cast把格式转换为32位浮点型\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for epoch in range(1001):\n",
    "        for batch in range(n_batch):\n",
    "            batch_xs,batch_ys = mnist.train.next_batch(batch_size)\n",
    "            sess.run(train_step,feed_dict = {x:batch_xs,y:batch_ys})\n",
    "        \n",
    "    acc = sess.run(accuracy,feed_dict = {x:mnist.test.images,y:mnist.test.labels})\n",
    "    print(\"lter , Testing Accuracy \"+str(acc))\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TensorFlow",
   "language": "python",
   "name": "tf-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
