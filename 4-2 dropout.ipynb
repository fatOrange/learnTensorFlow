{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow  as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data\\train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data\\train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data\\t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data\\t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "OOM when allocating tensor with shape[55000,2000] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[node dropout_3/div (defined at <ipython-input-3-ca76fb999c0f>:21)  = RealDiv[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](Tanh_3, _arg_Placeholder_5_0_2/_13)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[{{node Mean_3/_15}} = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_80_Mean_3\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\nCaused by op 'dropout_3/div', defined at:\n  File \"C:\\Users\\NUAAOrange\\Anaconda3\\envs\\tf-gpu\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"C:\\Users\\NUAAOrange\\Anaconda3\\envs\\tf-gpu\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"C:\\Users\\NUAAOrange\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"C:\\Users\\NUAAOrange\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"C:\\Users\\NUAAOrange\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 505, in start\n    self.io_loop.start()\n  File \"C:\\Users\\NUAAOrange\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 132, in start\n    self.asyncio_loop.run_forever()\n  File \"C:\\Users\\NUAAOrange\\Anaconda3\\envs\\tf-gpu\\lib\\asyncio\\base_events.py\", line 427, in run_forever\n    self._run_once()\n  File \"C:\\Users\\NUAAOrange\\Anaconda3\\envs\\tf-gpu\\lib\\asyncio\\base_events.py\", line 1440, in _run_once\n    handle._run()\n  File \"C:\\Users\\NUAAOrange\\Anaconda3\\envs\\tf-gpu\\lib\\asyncio\\events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"C:\\Users\\NUAAOrange\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tornado\\ioloop.py\", line 758, in _run_callback\n    ret = callback()\n  File \"C:\\Users\\NUAAOrange\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tornado\\stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\Users\\NUAAOrange\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tornado\\gen.py\", line 1233, in inner\n    self.run()\n  File \"C:\\Users\\NUAAOrange\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tornado\\gen.py\", line 1147, in run\n    yielded = self.gen.send(value)\n  File \"C:\\Users\\NUAAOrange\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 357, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"C:\\Users\\NUAAOrange\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tornado\\gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"C:\\Users\\NUAAOrange\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 267, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"C:\\Users\\NUAAOrange\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tornado\\gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"C:\\Users\\NUAAOrange\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 534, in execute_request\n    user_expressions, allow_stdin,\n  File \"C:\\Users\\NUAAOrange\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tornado\\gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"C:\\Users\\NUAAOrange\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 294, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"C:\\Users\\NUAAOrange\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"C:\\Users\\NUAAOrange\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2819, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"C:\\Users\\NUAAOrange\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2845, in _run_cell\n    return runner(coro)\n  File \"C:\\Users\\NUAAOrange\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 67, in _pseudo_sync_runner\n    coro.send(None)\n  File \"C:\\Users\\NUAAOrange\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3020, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"C:\\Users\\NUAAOrange\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3185, in run_ast_nodes\n    if (yield from self.run_code(code, result)):\n  File \"C:\\Users\\NUAAOrange\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3267, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-3-ca76fb999c0f>\", line 21, in <module>\n    L1_drop = tf.nn.dropout(L1,keep_prob)#keep_prob设置有多少神经元工作0-1\n  File \"C:\\Users\\NUAAOrange\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py\", line 2326, in dropout\n    ret = math_ops.div(x, keep_prob) * binary_tensor\n  File \"C:\\Users\\NUAAOrange\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py\", line 1053, in div\n    return _div_python2(x, y, name)\n  File \"C:\\Users\\NUAAOrange\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py\", line 997, in _div_python2\n    return gen_math_ops.real_div(x, y, name=name)\n  File \"C:\\Users\\NUAAOrange\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\ops\\gen_math_ops.py\", line 5989, in real_div\n    \"RealDiv\", x=x, y=y, name=name)\n  File \"C:\\Users\\NUAAOrange\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"C:\\Users\\NUAAOrange\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\", line 488, in new_func\n    return func(*args, **kwargs)\n  File \"C:\\Users\\NUAAOrange\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3274, in create_op\n    op_def=op_def)\n  File \"C:\\Users\\NUAAOrange\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1770, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[55000,2000] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[node dropout_3/div (defined at <ipython-input-3-ca76fb999c0f>:21)  = RealDiv[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](Tanh_3, _arg_Placeholder_5_0_2/_13)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[{{node Mean_3/_15}} = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_80_Mean_3\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1333\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1334\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1335\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[1;32m-> 1319\u001b[1;33m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[0;32m   1320\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1407\u001b[1;33m         run_metadata)\n\u001b[0m\u001b[0;32m   1408\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[55000,2000] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node dropout_3/div}} = RealDiv[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](Tanh_3, _arg_Placeholder_5_0_2/_13)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[{{node Mean_3/_15}} = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_80_Mean_3\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-ca76fb999c0f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     60\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     61\u001b[0m         \u001b[0mtest_acc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mmnist\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimages\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mmnist\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mkeep_prob\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m1.0\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 62\u001b[1;33m         \u001b[0mtrain_acc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mmnist\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimages\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mmnist\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mkeep_prob\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m1.0\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     63\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Iter \"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\",Testing Accuracy \"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_acc\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\",Training Accuracy \"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_acc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    927\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 929\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    930\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1150\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1152\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1153\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1326\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1328\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1329\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1330\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1346\u001b[0m           \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1347\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0merror_interpolation\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minterpolate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1348\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1349\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1350\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[55000,2000] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[node dropout_3/div (defined at <ipython-input-3-ca76fb999c0f>:21)  = RealDiv[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](Tanh_3, _arg_Placeholder_5_0_2/_13)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[{{node Mean_3/_15}} = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_80_Mean_3\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\nCaused by op 'dropout_3/div', defined at:\n  File \"C:\\Users\\NUAAOrange\\Anaconda3\\envs\\tf-gpu\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"C:\\Users\\NUAAOrange\\Anaconda3\\envs\\tf-gpu\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"C:\\Users\\NUAAOrange\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"C:\\Users\\NUAAOrange\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"C:\\Users\\NUAAOrange\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 505, in start\n    self.io_loop.start()\n  File \"C:\\Users\\NUAAOrange\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 132, in start\n    self.asyncio_loop.run_forever()\n  File \"C:\\Users\\NUAAOrange\\Anaconda3\\envs\\tf-gpu\\lib\\asyncio\\base_events.py\", line 427, in run_forever\n    self._run_once()\n  File \"C:\\Users\\NUAAOrange\\Anaconda3\\envs\\tf-gpu\\lib\\asyncio\\base_events.py\", line 1440, in _run_once\n    handle._run()\n  File \"C:\\Users\\NUAAOrange\\Anaconda3\\envs\\tf-gpu\\lib\\asyncio\\events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"C:\\Users\\NUAAOrange\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tornado\\ioloop.py\", line 758, in _run_callback\n    ret = callback()\n  File \"C:\\Users\\NUAAOrange\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tornado\\stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\Users\\NUAAOrange\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tornado\\gen.py\", line 1233, in inner\n    self.run()\n  File \"C:\\Users\\NUAAOrange\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tornado\\gen.py\", line 1147, in run\n    yielded = self.gen.send(value)\n  File \"C:\\Users\\NUAAOrange\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 357, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"C:\\Users\\NUAAOrange\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tornado\\gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"C:\\Users\\NUAAOrange\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 267, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"C:\\Users\\NUAAOrange\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tornado\\gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"C:\\Users\\NUAAOrange\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 534, in execute_request\n    user_expressions, allow_stdin,\n  File \"C:\\Users\\NUAAOrange\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tornado\\gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"C:\\Users\\NUAAOrange\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 294, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"C:\\Users\\NUAAOrange\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"C:\\Users\\NUAAOrange\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2819, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"C:\\Users\\NUAAOrange\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2845, in _run_cell\n    return runner(coro)\n  File \"C:\\Users\\NUAAOrange\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 67, in _pseudo_sync_runner\n    coro.send(None)\n  File \"C:\\Users\\NUAAOrange\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3020, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"C:\\Users\\NUAAOrange\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3185, in run_ast_nodes\n    if (yield from self.run_code(code, result)):\n  File \"C:\\Users\\NUAAOrange\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3267, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-3-ca76fb999c0f>\", line 21, in <module>\n    L1_drop = tf.nn.dropout(L1,keep_prob)#keep_prob设置有多少神经元工作0-1\n  File \"C:\\Users\\NUAAOrange\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py\", line 2326, in dropout\n    ret = math_ops.div(x, keep_prob) * binary_tensor\n  File \"C:\\Users\\NUAAOrange\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py\", line 1053, in div\n    return _div_python2(x, y, name)\n  File \"C:\\Users\\NUAAOrange\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py\", line 997, in _div_python2\n    return gen_math_ops.real_div(x, y, name=name)\n  File \"C:\\Users\\NUAAOrange\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\ops\\gen_math_ops.py\", line 5989, in real_div\n    \"RealDiv\", x=x, y=y, name=name)\n  File \"C:\\Users\\NUAAOrange\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"C:\\Users\\NUAAOrange\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\", line 488, in new_func\n    return func(*args, **kwargs)\n  File \"C:\\Users\\NUAAOrange\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3274, in create_op\n    op_def=op_def)\n  File \"C:\\Users\\NUAAOrange\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1770, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[55000,2000] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[node dropout_3/div (defined at <ipython-input-3-ca76fb999c0f>:21)  = RealDiv[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](Tanh_3, _arg_Placeholder_5_0_2/_13)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[{{node Mean_3/_15}} = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_80_Mean_3\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n"
     ]
    }
   ],
   "source": [
    "#载入数据集\n",
    "mnist = input_data.read_data_sets(\"MNIST_data\",one_hot=True)\n",
    "\n",
    "#每个批次的大小\n",
    "batch_size = 100\n",
    "#计算一共有多少个批次\n",
    "n_batch = mnist.train.num_examples // batch_size\n",
    "\n",
    "#定义两个placeholder\n",
    "x = tf.placeholder(tf.float32,[None,784])\n",
    "y = tf.placeholder(tf.float32,[None,10])\n",
    "keep_prob = tf.placeholder(tf.float32 )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#创建一个简单的神经网络\n",
    "W1 = tf.Variable(tf.truncated_normal([784,2000],stddev=0.1))\n",
    "b1 = tf.Variable(tf.zeros([2000])+0.1)\n",
    "L1 = tf.nn.tanh(tf.matmul(x,W1)+b1)\n",
    "L1_drop = tf.nn.dropout(L1,keep_prob)#keep_prob设置有多少神经元工作0-1\n",
    "\n",
    "W2 = tf.Variable(tf.truncated_normal([2000,2000],stddev=0.1))\n",
    "b2 = tf.Variable(tf.zeros([2000])+0.1)\n",
    "L2 = tf.nn.tanh(tf.matmul(L1_drop,W2)+b2)\n",
    "L2_drop = tf.nn.dropout(L2,keep_prob)\n",
    "\n",
    "W3 = tf.Variable(tf.truncated_normal([2000,1000],stddev=0.1))\n",
    "b3 = tf.Variable(tf.zeros([1000])+0.1)\n",
    "L3 = tf.nn.tanh(tf.matmul(L2_drop,W3)+b3)\n",
    "L3_drop = tf.nn.dropout(L3,keep_prob)\n",
    "\n",
    "W4 = tf.Variable(tf.truncated_normal([1000,10],stddev=0.1))\n",
    "b4 = tf.Variable(tf.zeros([10])+0.1)\n",
    "prediction = tf.nn.softmax(tf.matmul(L3_drop,W4)+b4)\n",
    "\n",
    "# prediction = tf.nn.softmax(tf.matmul(x,W)+b)\n",
    "# prediction = tf.nn.softmax(tf.matmul(x,W4)+b4)\n",
    "\n",
    "#二次代价函数\n",
    "# loss = tf.reduce_mean(tf.square(y-prediction))\n",
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y,logits=prediction))\n",
    "#使用梯度下降法\n",
    "train_step = tf.train.GradientDescentOptimizer(0.2).minimize(loss)\n",
    "\n",
    "#初始化变量\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "#结果存放在一个布尔型列表中\n",
    "correct_prediction = tf.equal(tf.argmax(y,1),tf.argmax(prediction,1))#argmax返回一维张量中最大的值所在的位置\n",
    "#求准确率\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction,tf.float32))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for epoch in range(31):\n",
    "        for batch in range(n_batch):\n",
    "            batch_xs,batch_ys =  mnist.train.next_batch(batch_size)\n",
    "            sess.run(train_step,feed_dict={x:batch_xs,y:batch_ys,keep_prob:0.7})\n",
    "        \n",
    "        test_acc = sess.run(accuracy,feed_dict={x:mnist.test.images,y:mnist.test.labels,keep_prob:1.0})\n",
    "        train_acc = sess.run(accuracy,feed_dict={x:mnist.train.images,y:mnist.train.labels,keep_prob:1.0})\n",
    "        print(\"Iter \" + str(epoch) + \",Testing Accuracy \" + str(test_acc) + \",Training Accuracy \" + str(train_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Iter 0,Testing Accuracy 0.9465,Training Accuracy 0.9580909\n",
    "Iter 1,Testing Accuracy 0.9592,Training Accuracy 0.9752909\n",
    "Iter 2,Testing Accuracy 0.9637,Training Accuracy 0.98267275\n",
    "Iter 3,Testing Accuracy 0.9669,Training Accuracy 0.98645455\n",
    "Iter 4,Testing Accuracy 0.9683,Training Accuracy 0.9884909\n",
    "Iter 5,Testing Accuracy 0.9692,Training Accuracy 0.9898546\n",
    "Iter 6,Testing Accuracy 0.9697,Training Accuracy 0.9906727\n",
    "Iter 7,Testing Accuracy 0.9703,Training Accuracy 0.99163634\n",
    "Iter 8,Testing Accuracy 0.9702,Training Accuracy 0.99234545\n",
    "Iter 9,Testing Accuracy 0.9705,Training Accuracy 0.9927818\n",
    "Iter 10,Testing Accuracy 0.9701,Training Accuracy 0.99325454\n",
    "Iter 11,Testing Accuracy 0.9711,Training Accuracy 0.9935091\n",
    "Iter 12,Testing Accuracy 0.9708,Training Accuracy 0.99381816\n",
    "Iter 13,Testing Accuracy 0.972,Training Accuracy 0.9941091\n",
    "Iter 14,Testing Accuracy 0.9708,Training Accuracy 0.99436367\n",
    "Iter 15,Testing Accuracy 0.9712,Training Accuracy 0.9944909\n",
    "Iter 16,Testing Accuracy 0.971,Training Accuracy 0.9946909\n",
    "Iter 17,Testing Accuracy 0.9714,Training Accuracy 0.99487275\n",
    "Iter 18,Testing Accuracy 0.9723,Training Accuracy 0.9950727\n",
    "Iter 19,Testing Accuracy 0.9722,Training Accuracy 0.99523634\n",
    "Iter 20,Testing Accuracy 0.9719,Training Accuracy 0.9953091\n",
    "Iter 21,Testing Accuracy 0.9715,Training Accuracy 0.99536365\n",
    "Iter 22,Testing Accuracy 0.9709,Training Accuracy 0.99545455\n",
    "Iter 23,Testing Accuracy 0.9718,Training Accuracy 0.9955636\n",
    "Iter 24,Testing Accuracy 0.9726,Training Accuracy 0.9956\n",
    "Iter 25,Testing Accuracy 0.9726,Training Accuracy 0.9956545\n",
    "Iter 26,Testing Accuracy 0.9718,Training Accuracy 0.99570906\n",
    "Iter 27,Testing Accuracy 0.9727,Training Accuracy 0.9957455\n",
    "Iter 28,Testing Accuracy 0.973,Training Accuracy 0.9958\n",
    "Iter 29,Testing Accuracy 0.9725,Training Accuracy 0.9958909\n",
    "Iter 30,Testing Accuracy 0.9718,Training Accuracy 0.9959818"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TensorFlow -GPU V2",
   "language": "python",
   "name": "tf-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
